{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conditional Median Inference Simulations",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PeSb7qR9jqK"
      },
      "source": [
        "# Conditional Median Inference Simulations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6tar0pt9q-r"
      },
      "source": [
        "This notebook replicates the simulations seen in Section 4 of [1]. Specifically, it tests the performance of the general Conditional Quantile Inference algorithm (Algorithm 2) on 3 distributions with 4 different conformity scores. There are 4 sections:\n",
        "\n",
        "\n",
        "1.   **Distributions** - Describes the distribution class and covers the 3 relevant distributions\n",
        "2.   **Conformity Scores** - Describes the conformity score class and covers the 4 relevant scores\n",
        "3.   **Conditional Quantile Algorithm** - Contains an implementation of Algorithm 2\n",
        "4.   **Testing Algorithm Performance** - Tests algorithm performance given each combination of distribution and conformity score\n",
        "\n",
        "\n",
        "\n",
        "[1] Dhruv Medarametla and Emmanuel CandÃ¨s, \"Distribution-Free Conditional Median Inference.\" 2021."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H83Rf7lTG8z8"
      },
      "source": [
        "!pip install scikit-garden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FHWaRDVAi2_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from datetime import datetime\n",
        "from sklearn.utils import shuffle\n",
        "import pickle\n",
        "import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Used to save images to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "from skgarden import RandomForestQuantileRegressor, RandomForestRegressor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ43rsE0lofC"
      },
      "source": [
        "\n",
        "metadata_dir = '/content/gdrive/My Drive/Conditional Median Inference/Metadata/'\n",
        "images_dir = '/content/gdrive/My Drive/Conditional Median Inference/Images/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmXtpNIzXN03"
      },
      "source": [
        "# Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbH7-B34XRQl"
      },
      "source": [
        "This section contains different distributions that can be passed into the conditional quantile inference algorithm to test performance. Each distribution contains a sampling method and a conditional quantile calculation method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP746maJAokF"
      },
      "source": [
        "### Distribution 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij5X_W1sXo0j"
      },
      "source": [
        "class NormalCorrelatedDistribution:\n",
        "\n",
        "  def __init__(self, d = 3, rho = 0, sigma = 1):\n",
        "    assert d >= 3, f\"Need d at least 3 but got {d}\"\n",
        "    self.mu = np.zeros(d)\n",
        "    self.Sigma = (1. - rho) * np.identity(d) + rho * np.ones((d,d))\n",
        "    self.resid_sigma = sigma\n",
        "\n",
        "  def get_stdev(self, X, n):\n",
        "    return 0.1 + 0.25 * np.square(np.linalg.norm(X, axis = 1)).reshape((n,1))\n",
        "\n",
        "  def sample(self, n):\n",
        "    X = np.random.multivariate_normal(mean = self.mu, cov = self.Sigma, size = n)\n",
        "    Y_mean = np.square(X[:,[0]] + X[:,[1]]) - X[:,[2]]\n",
        "    Y_resid = np.multiply(self.get_stdev(X, n), np.random.normal(loc = 0., scale = self.resid_sigma, size = (n,1)))\n",
        "    Y = Y_mean + Y_resid\n",
        "    return X, Y\n",
        "\n",
        "  def get_quantile(self, X, q):\n",
        "    Y_mean = np.square(X[:,[0]] + X[:,[1]]) - X[:,[2]]\n",
        "    Y_quantile = self.get_stdev(X, X.shape[0]) * norm.ppf(q, loc = 0., scale = self.resid_sigma)\n",
        "    return Y_mean + Y_quantile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy_RGXMPAqbv"
      },
      "source": [
        "### Distribution 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBoXpJ3TijCZ"
      },
      "source": [
        "class IncreasingVarianceDistribution:\n",
        "\n",
        "  def __init__(self, scale = np.pi, power = 1.):\n",
        "    assert scale > 0, f\"Need positive scale but got {scale}\"\n",
        "    assert power > 0, f\"Need positive power but got {power}\"\n",
        "    self.scale = scale\n",
        "    self.power = power\n",
        "\n",
        "  def f(self, X):\n",
        "    return 1 + np.abs(X) * np.square(np.sin(X))\n",
        "\n",
        "  def sample(self, n):\n",
        "    X = np.random.uniform(low = -1. * self.scale, high = self.scale, size = (n,1))\n",
        "    Y = self.f(X) * (np.random.uniform(low = 0., high = 1., size = (n,1)) ** self.power)\n",
        "    return X, Y\n",
        "\n",
        "  def get_quantile(self, X, q):\n",
        "    return self.f(X) * (np.full(shape = (X.shape[0], 1), fill_value = q) ** self.power)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSBZWn_DAseu"
      },
      "source": [
        "### Distribution 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P77T6U7lltWF"
      },
      "source": [
        "class ConfusingDistribution:\n",
        "\n",
        "  def __init__(self, delta = 0.01, M = 10):\n",
        "    assert delta > 0 and delta <= 0.25, f\"Need delta in (0, 0.25] but got {delta}\"\n",
        "    assert isinstance(M, int) and M > 0, f\"Need M to be a positive integer but got {M}\"\n",
        "    self.delta = delta\n",
        "    self.M = M\n",
        "    self.gamma = 1. / M\n",
        "\n",
        "  def f(self, X):\n",
        "    integral_part, fractional_part = np.divmod(X * self.M, 1.)\n",
        "    return self.gamma * fractional_part - self.gamma / 2. - ((-1) ** (integral_part)) * (1. - self.gamma / 2.)\n",
        "\n",
        "  def sample(self, n):\n",
        "    X = np.random.uniform(low = -1., high = 1., size = (n,1))\n",
        "    Y = self.f(X) * np.random.binomial(n = 1, p = 0.5 + 2 * self.delta, size = (n,1))\n",
        "    return X, Y\n",
        "\n",
        "  def get_quantile(self, X, q):\n",
        "    nonzero_values = self.f(X)\n",
        "    return (np.sign(nonzero_values) * (q - 0.5) >= -2. * self.delta) * nonzero_values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foK92D8tt8O4"
      },
      "source": [
        "## Distribution Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCqARLQEuEYJ"
      },
      "source": [
        "We plot the distributions, as well as the conditional medians, of Distributions 2 and 3. For Distribution 1, we cannot plot the full distribution due to dimensionality; we instead plot the distribution of the datapoints as well as the distribution of the conditional median."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjyvUfigvhko"
      },
      "source": [
        "n = 10000\n",
        "q = 0.5\n",
        "\n",
        "bins = 150\n",
        "\n",
        "save_figs = False\n",
        "dpi = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkiyR-wrvVCn"
      },
      "source": [
        "distribution1 = NormalCorrelatedDistribution(d = 10, rho = 0.25, sigma = 1)\n",
        "X, Y = distribution1.sample(n)\n",
        "Y_median = distribution1.get_quantile(X, q)\n",
        "\n",
        "plt.hist(Y, density = True, bins = bins, alpha = 1, color = 'c', label = 'Datapoints')\n",
        "plt.hist(Y_median, density = True, bins = bins, alpha = 0.5, color = 'r', label = 'Conditional Median')\n",
        "plt.legend()\n",
        "plt.xlabel('Y')\n",
        "plt.ylabel('Density')\n",
        "plt.title(r'$P_1$ Y Distribution and Conditional Median Distribution')\n",
        "\n",
        "if save_figs:\n",
        "  filename = \"Distribution 1.pdf\"\n",
        "  plt.savefig(images_dir + filename)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta7r3miI6a6O"
      },
      "source": [
        "datapoint_size = 5\n",
        "datapoint_color = 'c'\n",
        "datapoint_scale = 2.\n",
        "\n",
        "median_linewidth = 2\n",
        "median_color = 'k'\n",
        "\n",
        "title_fontsize = 16\n",
        "label_fontsize = 14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkWmmvXV43B5"
      },
      "source": [
        "scale = 4 * np.pi\n",
        "power = 0.25\n",
        "\n",
        "distribution2 = IncreasingVarianceDistribution(scale = scale, power = power)\n",
        "X, Y = distribution2.sample(n)\n",
        "\n",
        "X_range = np.linspace(start = -1. * scale, stop = scale, num = n)\n",
        "Y_median = distribution2.get_quantile(X_range.reshape((n,1)), 0.5)\n",
        "\n",
        "plt.figure(figsize = (5,4))\n",
        "plt.tight_layout()\n",
        "plt.scatter(X,Y, s = datapoint_size, color = datapoint_color, label = 'Datapoints')\n",
        "plt.plot(X_range, Y_median, color = median_color, linewidth = median_linewidth, label = 'Conditional Median')\n",
        "plt.legend(markerscale= datapoint_scale)\n",
        "\n",
        "plt.xlabel(r\"$X$\", fontsize = label_fontsize)\n",
        "plt.ylabel(r\"$Y$\", fontsize = label_fontsize)\n",
        "plt.title(r\"$P_2$\", fontsize = title_fontsize)\n",
        "\n",
        "save_figs = True\n",
        "if save_figs:\n",
        "  filename = \"Distribution 2.pdf\"\n",
        "  plt.savefig(images_dir + filename,bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0OkDB4L8wqC"
      },
      "source": [
        "M = 25\n",
        "delta = 0.0001\n",
        "gamma = 1./M\n",
        "\n",
        "distribution3 = ConfusingDistribution(delta = delta, M = M)\n",
        "X, Y = distribution3.sample(n)\n",
        "\n",
        "plt.figure(figsize = (5,4))\n",
        "plt.tight_layout()\n",
        "plt.scatter(X,Y, s = 8, color = datapoint_color, label = 'Datapoints')\n",
        "plt.plot([0, 0], [-1, -1], color = median_color, linewidth = median_linewidth, label = 'Conditional Median')\n",
        "\n",
        "for i in range(-M, M):\n",
        "  if (i % 2) == 0:\n",
        "    plt.plot([gamma * i, gamma * i + gamma], [-1, -1 + gamma], color = median_color, linewidth = median_linewidth)\n",
        "  if (i % 2) == 1:\n",
        "    plt.plot([gamma * i, gamma * i + gamma], [1 - gamma, 1], color = median_color, linewidth = median_linewidth)\n",
        "\n",
        "\n",
        "plt.ylim((-1.1, 1.6))\n",
        "plt.legend(markerscale= 1.5, loc = 'upper center')\n",
        "\n",
        "plt.xlabel(r\"$X$\", fontsize = label_fontsize)\n",
        "plt.ylabel(r\"$Y$\", fontsize = label_fontsize)\n",
        "plt.title(r\"$P_3$\", fontsize = title_fontsize)\n",
        "\n",
        "save_figs = True\n",
        "if save_figs:\n",
        "  filename = \"Distribution 3.pdf\"\n",
        "  plt.savefig(images_dir + filename,bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0W6FIc0Ac9W"
      },
      "source": [
        "# Conformity Scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAqwyEOSAnm6"
      },
      "source": [
        "This section contains different conformity scores that can be passed into the conditional median inference algorithm. Each score contains a training method, a scoring method, and an inverse method. Note that we use a random forest predictor for all 4 conformity scores; for the first two, we train a random forest to predict the conditional mean, while the last two train a random forest to predict the conditional quantile."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achpIoZPA8bF"
      },
      "source": [
        "### Conformity Score 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFg6dQJMAmJp"
      },
      "source": [
        "class LinearDistanceConformityScore:\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    self.mu = RandomForestRegressor(**kwargs)\n",
        "\n",
        "  def train(self, X, Y):\n",
        "    self.mu.fit(X, Y)\n",
        "\n",
        "  def score(self, X, Y):\n",
        "    n = X.shape[0]\n",
        "    prediction = self.mu.predict(X).reshape((n,1))\n",
        "    return Y - prediction\n",
        "\n",
        "  def inverse(self, X, score):\n",
        "    n = X.shape[0]\n",
        "    prediction = self.mu.predict(X).reshape((n,1))\n",
        "    return prediction + score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFui0pCtA-TF"
      },
      "source": [
        "### Conformity Score 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Qd6oO6K1Ak"
      },
      "source": [
        "class NormalizedDistanceConformityScore: \n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "    self.mu = RandomForestRegressor(**kwargs)\n",
        "\n",
        "  def train(self, X, Y):\n",
        "    self.mu.fit(X, Y)\n",
        "\n",
        "  def score(self, X, Y):\n",
        "    n = X.shape[0]\n",
        "    prediction, std = self.mu.predict(X, return_std = True)\n",
        "    prediction = prediction.reshape((n,1))\n",
        "    std = std.reshape((n,1))\n",
        "    return (Y - prediction) / std\n",
        "\n",
        "  def inverse(self, X, score):\n",
        "    n = X.shape[0]\n",
        "    prediction, std = self.mu.predict(X, return_std = True)\n",
        "    prediction = prediction.reshape((n,1))\n",
        "    std = std.reshape((n,1))\n",
        "    return prediction + score * std\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR7NEMdOA_4F"
      },
      "source": [
        "### Conformity Score 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2GC2KZDLkST"
      },
      "source": [
        "class QuantileDistanceConformityScore:\n",
        "\n",
        "  def __init__(self, quantile = None, **kwargs):\n",
        "    self.mu = RandomForestQuantileRegressor(**kwargs)\n",
        "    self.quantile = 100 * quantile\n",
        "\n",
        "  def train(self, X, Y):\n",
        "    self.mu.fit(X, Y)\n",
        "\n",
        "  def score(self, X, Y):\n",
        "    n = X.shape[0]\n",
        "    prediction = self.mu.predict(X, quantile = self.quantile).reshape((n,1))\n",
        "    return Y - prediction\n",
        "\n",
        "  def inverse(self, X, score):\n",
        "    n = X.shape[0]\n",
        "    prediction = self.mu.predict(X, quantile = self.quantile).reshape((n,1))\n",
        "    return prediction + score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p94_lk11BBgl"
      },
      "source": [
        "### Conformity Score 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds7CZqguMmd5"
      },
      "source": [
        "class InverseCDFConformityScore:\n",
        "\n",
        "  quantile_list = [0,1,2,3,4,5,10,20,30,40,50,60,70,80,90,95,96,97,98,99,100]\n",
        "\n",
        "  def __init__(self, quantiles = None, **kwargs):\n",
        "    self.mu = RandomForestQuantileRegressor(**kwargs)\n",
        "    if quantiles:\n",
        "      self.quantiles = quantiles\n",
        "    else:\n",
        "      self.quantiles = self.quantile_list\n",
        "\n",
        "  def train(self, X, Y):\n",
        "    self.mu.fit(X, Y)\n",
        "\n",
        "  def score_individual(self, X_i, Y_i):\n",
        "    Y_value = Y_i[0,0]\n",
        "    quantile_predictions = {}\n",
        "\n",
        "    low_index = 0\n",
        "    high_index = len(self.quantiles) - 1\n",
        "    mid_index = 0\n",
        "\n",
        "    while low_index + 1 < high_index:\n",
        "      mid_index = int((low_index + high_index) / 2)\n",
        "      mid_value = self.quantiles[mid_index]\n",
        "      quantile_predictions[mid_value] = self.mu.predict(X_i, quantile = mid_value)[0]\n",
        "\n",
        "      if quantile_predictions[mid_value] < Y_value:\n",
        "        low_index = mid_index\n",
        "      elif quantile_predictions[mid_value] > Y_value:\n",
        "        high_index = mid_index\n",
        "      else:\n",
        "        return mid_value\n",
        "\n",
        "    low_value = self.quantiles[low_index]\n",
        "    high_value = self.quantiles[high_index]\n",
        "    if low_value not in quantile_predictions:\n",
        "      quantile_predictions[low_value] = self.mu.predict(X_i, quantile = low_value)[0]\n",
        "    if high_value not in quantile_predictions:\n",
        "      quantile_predictions[high_value] = self.mu.predict(X_i, quantile = high_value)[0]\n",
        "\n",
        "    if Y_value < quantile_predictions[low_value]:\n",
        "      return self.quantiles[0] + Y_value - quantile_predictions[low_value]\n",
        "    if Y_value > quantile_predictions[high_value]:\n",
        "      return self.quantiles[-1] + Y_value - quantile_predictions[high_value]\n",
        "    return np.interp(Y_value, [quantile_predictions[low_value], quantile_predictions[high_value]], [low_value, high_value])\n",
        "\n",
        "  def score(self, X, Y):\n",
        "    n = X.shape[0]\n",
        "    scores = np.zeros((n, 1))\n",
        "\n",
        "    for i in range(n):\n",
        "      X_i = X[[i],:]\n",
        "      Y_i = Y[[i],:]\n",
        "      scores[i, 0] = self.score_individual(X_i, Y_i)\n",
        "    return scores\n",
        "\n",
        "  def inverse_individual(self, X_i, score_i):\n",
        "    score_value = score_i[0,0]\n",
        "    quantile_predictions = {}\n",
        "\n",
        "    if score_value < self.quantiles[0]:\n",
        "      quantile_predictions[self.quantiles[0]] = self.mu.predict(X_i, quantile = self.quantiles[0])[0]\n",
        "      return quantile_predictions[self.quantiles[0]] + score_value - self.quantiles[0]\n",
        "    if score_value > self.quantiles[-1]:\n",
        "      quantile_predictions[self.quantiles[-1]] = self.mu.predict(X_i, quantile = self.quantiles[-1])[0]\n",
        "      return quantile_predictions[self.quantiles[-1]] + score_value - self.quantiles[-1]\n",
        "\n",
        "    low_index = np.searchsorted(self.quantiles, score_value, side = 'right') - 1\n",
        "    high_index = np.searchsorted(self.quantiles, score_value, side = 'left')\n",
        "    low_value = self.quantiles[low_index]\n",
        "    high_value = self.quantiles[high_index]\n",
        "    if low_value not in quantile_predictions:\n",
        "      quantile_predictions[low_value] = self.mu.predict(X_i, quantile = low_value)[0]\n",
        "    if high_value not in quantile_predictions:\n",
        "      quantile_predictions[high_value] = self.mu.predict(X_i, quantile = high_value)[0]\n",
        "    return np.interp(score_value, [low_value,high_value], [quantile_predictions[low_value], quantile_predictions[high_value]])\n",
        "  \n",
        "  def inverse(self, X, score):\n",
        "    n = X.shape[0]\n",
        "    inverses = np.zeros((n, 1))\n",
        "\n",
        "    for i in range(n):\n",
        "      X_i = X[[i],:]\n",
        "      score_i = score[[i],:]\n",
        "      inverses[i, 0] = self.inverse_individual(X_i, score_i)\n",
        "    return inverses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShmJcXwFy-ll"
      },
      "source": [
        "# Conditional Quantile Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfqXeKbmzCsK"
      },
      "source": [
        "This section contains the conditional quantile algorithm (Algorithm 2). It contains a train and test method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wFzVcFLzjhM"
      },
      "source": [
        "class ConditionalMedianAlgorithm:\n",
        "\n",
        "  def __init__(self, conformity_score_low, conformity_score_high, \n",
        "               alpha = 0.1, quantile = 0.5, \n",
        "               data_split_proportion = 0.5, probability_split_proportion = 0.5):\n",
        "    \n",
        "    assert alpha > 0 and alpha < 1, f\"Need alpha to be in (0,1) but got {alpha}\"\n",
        "    assert quantile > 0 and quantile < 1, f\"Need quantile to be in (0,1) but got {quantile}\"\n",
        "    assert data_split_proportion > 0 and quantile < 1, f\"Need data_split_proportion to be in (0,1) but got {data_split_proportion}\"\n",
        "    assert probability_split_proportion > 0 and probability_split_proportion < 1, f\"Need probability_split_proportion to be in (0,1) but got {probability_split_proportion}\"\n",
        "\n",
        "\n",
        "    self.f_lo = conformity_score_low\n",
        "    self.f_hi = conformity_score_high\n",
        "    self.alpha = alpha\n",
        "    self.q = quantile\n",
        "    self.data_split_proportion = data_split_proportion\n",
        "    self.probability_split_proportion = probability_split_proportion\n",
        "\n",
        "    self.r = alpha * probability_split_proportion\n",
        "    self.s = alpha * (1. - probability_split_proportion)\n",
        "\n",
        "  def train(self, X, Y):\n",
        "    n = X.shape[0]\n",
        "    assert Y.shape[0] == n, f\"Need X and Y to be 2-dimensional arrays with equal number of rows but got X.shape={X.shape} and Y.shape={Y.shape}\"\n",
        "\n",
        "    n_1 = int(n * self.data_split_proportion)\n",
        "    n_2 = n - n_1\n",
        "    X_shuffled, Y_shuffled = shuffle(X, Y)\n",
        "    X_I_1 = X_shuffled[:n_1, :]\n",
        "    X_I_2 = X_shuffled[n_1:, :]\n",
        "    Y_I_1 = Y_shuffled[:n_1, :]\n",
        "    Y_I_2 = Y_shuffled[n_1:, :]\n",
        "\n",
        "    self.f_lo.train(X_I_1, Y_I_1)\n",
        "    self.f_hi.train(X_I_1, Y_I_1)\n",
        "\n",
        "    f_lo_scores = self.f_lo.score(X_I_2, Y_I_2).flatten()\n",
        "    f_hi_scores = self.f_hi.score(X_I_2, Y_I_2).flatten()\n",
        "\n",
        "    lower_quantile = self.r * self.q * (1. + 1. / n_2) - 1. / n_2\n",
        "    upper_quantile = (1 - self.s * (1 - self.q)) * (1. + 1. / n_2)\n",
        "\n",
        "    self.lower_score_bound = np.quantile(f_lo_scores, lower_quantile)\n",
        "    self.upper_score_bound = np.quantile(f_hi_scores, upper_quantile)\n",
        "\n",
        "  def test(self, X):\n",
        "    n = X.shape[0]\n",
        "    CI_lower = self.f_lo.inverse(X, np.full((n, 1), fill_value = self.lower_score_bound))\n",
        "    CI_upper = self.f_hi.inverse(X, np.full((n, 1), fill_value = self.upper_score_bound))\n",
        "    return np.concatenate((CI_lower, CI_upper), axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHPO_0kE3Woo"
      },
      "source": [
        "# Quantile Forest Regression Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50oeDiXy3ft0"
      },
      "source": [
        "This section contains a nonconformalized quantile regression algorithm. It is intended to be used to compare performance against."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osjfhj4J1ve4"
      },
      "source": [
        "class RawMedianRandomForest:\n",
        "\n",
        "  def __init__(self, alpha = 0.1, quantile = 0.5, **kwargs):\n",
        "    assert alpha > 0 and alpha < 1, f\"Need alpha to be in (0,1) but got {alpha}\"\n",
        "    \n",
        "    self.alpha = alpha\n",
        "    self.lower_quantile = 100 * (self.alpha / 2)\n",
        "    self.upper_quantile = 100 * (1 - self.alpha / 2)\n",
        "    self.mu = RandomForestQuantileRegressor(**kwargs)\n",
        "    \n",
        "  def train(self, X, Y):\n",
        "    self.mu.fit(X, Y)\n",
        "\n",
        "  def test(self, X):\n",
        "    n = X.shape[0]\n",
        "    CI_lower = self.mu.predict(X, quantile = self.lower_quantile).reshape((n,1))\n",
        "    CI_upper = self.mu.predict(X, quantile = self.upper_quantile).reshape((n,1))\n",
        "    return np.concatenate((CI_lower, CI_upper), axis = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRrZ70wlJqM-"
      },
      "source": [
        "# Testing Algorithm Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GkzPEz_Jsej"
      },
      "source": [
        "We now go over the performance of the Conditional Median Algorithm by testing its performance on different distributions and conformity scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NvlsB4wmzzB"
      },
      "source": [
        "### Simulation Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Of0J8BympAM"
      },
      "source": [
        "alpha = 0.1\n",
        "\n",
        "num_trials = 500\n",
        "\n",
        "n_train = 5000\n",
        "n_test = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKs7CUOkCAJ0"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnR6UEJuLKi7"
      },
      "source": [
        "def get_indices_accurate(values, CI):\n",
        "  return np.logical_and(np.less_equal(CI[:,[0]], values), np.less_equal(values, CI[:,[1]]))\n",
        "\n",
        "def get_proportion_accurate(values, CI):\n",
        "  return np.average(get_indices_accurate(values, CI))\n",
        "\n",
        "def get_widths(CI):\n",
        "  return CI[:,[1]] - CI[:,[0]]\n",
        "\n",
        "def get_avg_width(CI):\n",
        "  return np.average(get_widths(CI))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx3YW3LgCDyK"
      },
      "source": [
        "### Distribution Parameter Specifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME6cPdntNO17"
      },
      "source": [
        "def get_dist(distribution):\n",
        "  if distribution == 1:\n",
        "    return NormalCorrelatedDistribution(d = 10, rho = 0.25, sigma = 1)\n",
        "  if distribution == 2:\n",
        "    return IncreasingVarianceDistribution(scale = 4 * np.pi, power = 0.25)\n",
        "  if distribution == 3:\n",
        "    return ConfusingDistribution(delta = 0.0001, M = 25)\n",
        "  assert f\"Need distribution to be 1, 2, or 3, but got {distribution}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCk6ZuCSCHxA"
      },
      "source": [
        "### Distribution Test Points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9beVpEPoDRD"
      },
      "source": [
        "dist_1_test_data = get_dist(1).sample(n_test)[0]\n",
        "dist_2_test_data = get_dist(2).sample(n_test)[0]\n",
        "dist_3_test_data = get_dist(3).sample(n_test)[0]\n",
        "\n",
        "def get_test_datapoints(distribution, n):\n",
        "  if distribution == 1:\n",
        "    return dist_1_test_data[:n, :]\n",
        "  if distribution == 2:\n",
        "    return dist_2_test_data[:n, :]\n",
        "  if distribution == 3:\n",
        "    return dist_3_test_data[:n, :]\n",
        "  assert f\"Need distribution to be 1, 2, or 3, but got {distribution}\"\n",
        "\n",
        "for dist_number in [1,2,3]:\n",
        "  test_datapoints = get_test_datapoints(dist_number, n_test)\n",
        "  output = open(metadata_dir + f\"Test Points/Distribution {dist_number}.pkl\", 'wb')\n",
        "  pickle.dump(test_datapoints, output)\n",
        "  output.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coZRQ1x8PRaD"
      },
      "source": [
        "def get_test_dist(dist_number):\n",
        "  with open(metadata_dir + f\"Test Points/Distribution {dist_number}.pkl\", 'rb') as handle:\n",
        "    return pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6TCBGRlB5Iz"
      },
      "source": [
        "### Random Forest Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS61VdNiNwZs"
      },
      "source": [
        "kwargs = {\"n_estimators\": 20,\n",
        "          \"min_samples_split\": 80,\n",
        "          \"min_samples_leaf\": 40}\n",
        "\n",
        "def get_scores(score, alpha):\n",
        "  if score == 1:\n",
        "    return LinearDistanceConformityScore(**kwargs), LinearDistanceConformityScore(**kwargs)\n",
        "  if score == 2:\n",
        "    return NormalizedDistanceConformityScore(**kwargs), NormalizedDistanceConformityScore(**kwargs)\n",
        "  if score == 3:\n",
        "    return QuantileDistanceConformityScore(quantile = alpha/2., criterion = \"mae\", **kwargs), QuantileDistanceConformityScore(quantile = 1. - alpha/2., criterion = \"mae\", **kwargs)\n",
        "  if score == 4:\n",
        "    return InverseCDFConformityScore(quantiles = None, criterion = \"mae\", **kwargs), InverseCDFConformityScore(quantiles = None, criterion = \"mae\", **kwargs)\n",
        "  assert f\"Need score to be 1, 2, 3, or 4, but got {score}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn3U-zkytDT7"
      },
      "source": [
        "### Singular Trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YszRc7vKh5Bj"
      },
      "source": [
        "def run_singular_trial(distribution_number, score_number, make_fig = True, save_fig = False, trial_num = 0, print_stats = False, save_results = False):\n",
        "  setup = f\"Distribution {distribution_number}; Conformity Score {score_number}; Trial {trial_num}\"\n",
        "  print(setup)\n",
        "  dist = get_dist(distribution_number)\n",
        "\n",
        "  ## Raw quantile regression algorithm\n",
        "  if score_number == 5:\n",
        "    algorithm = RawMedianRandomForest(alpha = alpha, n_estimators = 20, min_samples_split = 160, min_samples_leaf = 80)\n",
        "  else:\n",
        "    f_lo, f_hi = get_scores(score_number, alpha = alpha)\n",
        "    algorithm = ConditionalMedianAlgorithm(conformity_score_low = f_lo, conformity_score_high = f_hi, alpha = alpha)\n",
        "\n",
        "  X_train, Y_train = dist.sample(n_train)\n",
        "  algorithm.train(X_train, Y_train)\n",
        "\n",
        "  X_test = get_test_dist(distribution_number)\n",
        "  Y_median_true = dist.get_quantile(X_test, 0.5)\n",
        "  Y_median_CI = algorithm.test(X_test)\n",
        "  prop_accurate = get_proportion_accurate(Y_median_true, Y_median_CI)\n",
        "  avg_width = get_avg_width(Y_median_CI)\n",
        "\n",
        "  if print_stats:\n",
        "    print(f\"Proportion Accurate: {prop_accurate}\")\n",
        "    print(f\"Average Width: {avg_width}\")\n",
        "\n",
        "  if make_fig and distribution_number in [2,3]:\n",
        "    plt.figure(figsize = (5,4))\n",
        "    plt.tight_layout()\n",
        "    plt.plot(X_test, Y_median_true, color = median_color, linewidth = median_linewidth, label = 'Conditional Median')\n",
        "    plt.fill_between(X_test.ravel(), Y_median_CI[:,[0]].ravel(), Y_median_CI[:,[1]].ravel(), label = 'Confidence Interval', color = 'r', alpha = 0.2)\n",
        "    plt.scatter(X_train, Y_train, s = 0.5, color = datapoint_color, alpha = 0.25, label = 'Datapoints')\n",
        "    plt.legend(markerscale = 5)\n",
        "\n",
        "    plt.xlabel(r\"$X$\", fontsize = label_fontsize)\n",
        "    plt.ylabel(r\"$Y$\", fontsize = label_fontsize)\n",
        "    plt.title(f\"Conformity Score {score_number}\", fontsize = title_fontsize)\n",
        "    if save_fig:\n",
        "      filename = f\"{setup}.{trial_num}.pdf\"\n",
        "      plt.savefig(images_dir + filename,bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "  if save_results:\n",
        "    output = open(metadata_dir + f\"Performance/Distribution{distribution_number}.Score{score_number}.Trial{trial_num}.pkl\", 'wb')\n",
        "    output_data = {'Coverage': get_indices_accurate(Y_median_true, Y_median_CI), 'Width': get_widths(Y_median_CI)}\n",
        "    pickle.dump(output_data, output)\n",
        "    output.close()\n",
        "\n",
        "  return get_indices_accurate(Y_median_true, Y_median_CI), get_widths(Y_median_CI)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjsA37OCYJ3"
      },
      "source": [
        "## Get Images of Singular Trial on Distribution 2 for all conformity scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx1ekYsNUsmP"
      },
      "source": [
        "distribution_number = 2\n",
        "\n",
        "for score_number in tqdm.tqdm([1,2,3,4]):\n",
        "  indices_acc, widths = run_singular_trial(distribution_number, score_number, make_fig = True, save_fig = True, trial_num = 0)\n",
        "\n",
        "  prop_accurate = np.average(indices_acc)\n",
        "  avg_width = np.average(widths)\n",
        "  performance = {\"Proportion Accurate\": prop_accurate,\n",
        "                \"Average Width\": avg_width}\n",
        "  output = open(images_dir + f\"Performance Distribution {distribution_number} Score {score_number}.pkl\", 'wb')\n",
        "  pickle.dump(performance, output)\n",
        "  output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFMK2OpqCiAn"
      },
      "source": [
        "## Run 500 trials for each combination of distribution and conformity score to test performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGeYLg7sWQXg"
      },
      "source": [
        "for score_number in [1,2,3,4,5]:\n",
        "  for dist_number in [1,2,3]:\n",
        "    for trial in tqdm.tqdm(num_trials):\n",
        "      run_singular_trial(dist_number, score_number, make_fig = False, save_fig = False, trial_num = trial + 1, save_results = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-J70Sw7DFlv"
      },
      "source": [
        "## Calculating Simulation Metrics \n",
        "\n",
        "We calculate the average rate of coverage, the standard deviation of rate of coverage, the minimal conditional coverage, the average confidence interval width, and the standard deviation of average confidence interval width."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3yIO1O7tb46"
      },
      "source": [
        "for score_number in [1,2,3,4,5]:\n",
        "  for dist_number in [1,2,3]:\n",
        "\n",
        "    statistics = {}\n",
        "\n",
        "    coverages = []\n",
        "    widths = []\n",
        "    for trial_num in tqdm.tqdm(range(1, num_trials)):\n",
        "      with open(metadata_dir + f\"Performance/Distribution{dist_number}.Score{score_number}.Trial{trial_num}.pkl\", 'rb') as handle:\n",
        "        output =  pickle.load(handle)\n",
        "      coverages.append(output['Coverage'])\n",
        "      widths.append(output['Width'])\n",
        "    coverages = np.array(coverages)\n",
        "    widths = np.array(widths)\n",
        "\n",
        "    statistics['AC'] = np.mean(np.mean(coverages, axis = 1))\n",
        "    statistics['SDAC'] = np.std(np.mean(coverages, axis = 1), ddof = 1)\n",
        "    statistics['MCC'] = np.min(np.mean(coverages, axis = 0))\n",
        "    statistics['AW'] = np.mean(np.mean(widths, axis = 1))\n",
        "    statistics['SDAW'] = np.std(np.mean(widths, axis = 1), ddof = 1)\n",
        "\n",
        "    output = open(metadata_dir + f\"Distribution{dist_number}.Score{score_number}.pkl\", 'wb')\n",
        "    pickle.dump(statistics, output)\n",
        "    output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPCQkK2gxIt8"
      },
      "source": [
        "## View Performance for any Distribution / Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq0Zc_Y92MMn"
      },
      "source": [
        "dist_number = 1\n",
        "score_number = 1\n",
        "\n",
        "with open(metadata_dir + f\"Distribution{dist_number}.Score{score_number}.pkl\", 'rb') as handle:\n",
        "  statistics =  pickle.load(handle)\n",
        "\n",
        "statistics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKp8k93_gMsT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}